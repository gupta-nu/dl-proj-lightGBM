Here's a **complete solution** for Scenario-1 with separate RNN and LSTM models for **next-word prediction** and **sentiment trend forecasting**, including visual comparisons:

---

### **Step 1: Preprocess Dataset (Cornell Movie Dialogs)**
```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load Cornell Movie Dialogs
!wget https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip
!unzip cornell_movie_dialogs_corpus.zip

# Load and preprocess dialogues
lines = open('cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\n')
dialogues = [line.split(' +++$+++ ')[-1] for line in lines if line.strip()]

# Tokenize and create sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(dialogues)
sequences = tokenizer.texts_to_sequences(dialogues)
vocab_size = len(tokenizer.word_index) + 1

# Generate next-word prediction data
max_len = 20  # Context window size
X, y = [], []
for seq in sequences:
    for i in range(1, len(seq)):
        X.append(seq[max(0, i-max_len):i])
        y.append(seq[i])
X = pad_sequences(X, maxlen=max_len, padding='pre')
y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)

# Split dataset
split = int(0.8 * len(X))
X_train, X_val = X[:split], X[split:]
y_train, y_val = y[:split], y[split:]

# Synthetic sentiment labels (0=neutral, 1=positive, 2=negative)
# For real use, replace with actual labels (e.g., using VADER sentiment analysis)
y_sentiment = np.random.randint(0, 3, len(dialogues))
```

---

### **Step 2: Next-Word Prediction with RNN and LSTM**
```python
def build_next_word_model(rnn_type='RNN'):
    model = tf.keras.Sequential([
        Embedding(vocab_size, 128, input_length=max_len),
        SimpleRNN(128, return_sequences=False) if rnn_type == 'RNN' else LSTM(128, return_sequences=False),
        Dense(vocab_size, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Train RNN
model_rnn = build_next_word_model(rnn_type='RNN')
history_rnn = model_rnn.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), verbose=0)

# Train LSTM
model_lstm = build_next_word_model(rnn_type='LSTM')
history_lstm = model_lstm.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), verbose=0)

# Plot comparison
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history_rnn.history['val_loss'], label='RNN Val Loss')
plt.plot(history_lstm.history['val_loss'], label='LSTM Val Loss')
plt.title('Validation Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_rnn.history['val_accuracy'], label='RNN Val Accuracy')
plt.plot(history_lstm.history['val_accuracy'], label='LSTM Val Accuracy')
plt.title('Validation Accuracy')
plt.legend()
plt.show()
```

---

### **Step 3: Sentiment Trend Forecasting with RNN and LSTM**
```python
# Pad sequences for sentiment analysis
X_sent = pad_sequences(sequences, maxlen=100, padding='pre')
y_sent = y_sentiment[:len(X_sent)]

# Split dataset
split = int(0.8 * len(X_sent))
X_sent_train, X_sent_val = X_sent[:split], X_sent[split:]
y_sent_train, y_sent_val = y_sent[:split], y_sent[split:]

def build_sentiment_model(rnn_type='RNN'):
    model = tf.keras.Sequential([
        Embedding(vocab_size, 128, input_length=100),
        SimpleRNN(64, return_sequences=False) if rnn_type == 'RNN' else LSTM(64, return_sequences=False),
        Dense(3, activation='softmax')
    ])
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Train RNN
model_sent_rnn = build_sentiment_model(rnn_type='RNN')
history_sent_rnn = model_sent_rnn.fit(X_sent_train, y_sent_train, epochs=10, validation_data=(X_sent_val, y_sent_val), verbose=0)

# Train LSTM
model_sent_lstm = build_sentiment_model(rnn_type='LSTM')
history_sent_lstm = model_sent_lstm.fit(X_sent_train, y_sent_train, epochs=10, validation_data=(X_sent_val, y_sent_val), verbose=0)

# Plot comparison
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history_sent_rnn.history['val_loss'], label='RNN Val Loss')
plt.plot(history_sent_lstm.history['val_loss'], label='LSTM Val Loss')
plt.title('Sentiment Validation Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_sent_rnn.history['val_accuracy'], label='RNN Val Accuracy')
plt.plot(history_sent_lstm.history['val_accuracy'], label='LSTM Val Accuracy')
plt.title('Sentiment Validation Accuracy')
plt.legend()
plt.show()
```

---

### **Step 4: Prediction Samples**
```python
# Next-word prediction example
def predict_next_word(text, model):
    seq = tokenizer.texts_to_sequences([text])[0]
    padded = pad_sequences([seq], maxlen=max_len, padding='pre')
    pred = model.predict(padded).argmax()
    return tokenizer.index_word.get(pred, '')

print("RNN Prediction:", predict_next_word("how are you", model_rnn))
print("LSTM Prediction:", predict_next_word("how are you", model_lstm))

# Sentiment prediction example
def predict_sentiment(text, model):
    seq = tokenizer.texts_to_sequences([text])[0]
    padded = pad_sequences([seq], maxlen=100, padding='pre')
    return model.predict(padded).argmax()

text_sample = "This movie was absolutely fantastic!"
print("RNN Sentiment:", predict_sentiment(text_sample, model_sent_rnn))
print("LSTM Sentiment:", predict_sentiment(text_sample, model_sent_lstm))
```

---

### **Key Improvements**:
1. **Separate Models**: Clear comparison between RNN and LSTM for both next-word and sentiment tasks.
2. **Visualizations**: Training curves for loss/accuracy.
3. **Prediction Samples**: Demonstrates practical usage.
4. **Real Data Handling**: Uses Cornell Movie Dialogs with synthetic sentiment labels (replace with real labels for production).

**Output**:
- Loss/accuracy plots for both tasks.
- Example predictions showing RNN vs LSTM behavior.
